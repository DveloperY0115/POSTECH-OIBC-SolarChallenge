{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import modules\n",
        "import sys\n",
        "\n",
        "sys.path.append('../')\n",
        "from functions import *"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and create dataframe object from the CSV file\n",
        "df = pd.read_csv('../Data/ProductionData/Weather-Energy_rev_time_hourly_data.csv')\n",
        "\n",
        "# print(df.info())\n",
        "\n",
        "print(df.head())                                                      "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cols = ['day', 'hour', 'temperature','wind_speed(m/s)','humidity(%)','solar_radiation(MJ/m^2)','energy']\n",
        "# cols = ['day','hour','temperature','wind_speed(m/s)','humidity(%)','solar_radiation(MJ/m^2)','energy']\n",
        "dataset = df.loc[:, cols]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset.index = df['time']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset['humidity(%)'] = 100 - dataset['humidity(%)']  "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_y = MinMaxScaler(copy=False)\n",
        "scaler_x = MinMaxScaler(copy=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find the index where our training data begins\n",
        "\n",
        "start_idx_531 = df[df['time']==\"2020-04-01 0:00\"].index.tolist()[0]\n",
        "end_idx_531 = df[df['time']==\"2020-05-31 0:00\"].index.tolist()[0]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = dataset.to_numpy()\n",
        "Y = dataset.loc[:, 'energy'].to_numpy()\n",
        "Y = np.reshape(Y, (-1, 1))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "energy_max = np.max(Y)\n",
        "energy_min = np.min(Y)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler_x.fit_transform(X)\n",
        "scaler_y.fit_transform(Y)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def scale_train_data(x_seq, y_seq, scaler_x, scaler_y):\n",
        "    \n",
        "#    x_scaled = scaler_x.fit_transform(x_seq)\n",
        "#    y_scaled = scaler_y.fit_transform(y_seq)\n",
        "    \n",
        "    scaler_x.fit_transform(x_seq)\n",
        "    scaler_y.fit_transform(y_seq)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def gen_train_data_hour(start_idx, end_idx, seq_in_days, target_hrs, stride, data_array, label_array):\n",
        "    \n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    num_data_in_seq = 24 * seq_in_days\n",
        "    \n",
        "    if (target_hrs < 0):\n",
        "        num_data_in_target_hrs = - target_hrs\n",
        "    else:\n",
        "        num_data_in_target_hrs = target_hrs\n",
        "    \n",
        "    train_data_starts_at = start_idx\n",
        "    train_data_ends_at = end_idx - num_data_in_seq - num_data_in_target_hrs\n",
        "    \n",
        "    for i in range(train_data_starts_at, train_data_ends_at, stride):\n",
        "        x_temp = data_array[i:i+num_data_in_seq].tolist()\n",
        "        y_temp = label_array[i+num_data_in_seq:i+num_data_in_seq+num_data_in_target_hrs]\n",
        "        y_temp = np.reshape(y_temp, (num_data_in_target_hrs, 1)).tolist()\n",
        "        \n",
        "        x.append(x_temp)\n",
        "        y.append(y_temp)\n",
        "        \n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    return x, y\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "trainX_531 = X[start_idx_531:end_idx_531,:]\n",
        "trainY_531 = Y[start_idx_531:end_idx_531,:]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract training data for prediction\n",
        "\n",
        "trainX_531, trainY_531 = gen_train_data_hour(start_idx_531, end_idx_531, 4, 24, 96, X, Y)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(trainX_531[0, :, 5])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The very first estimations are not accurate, and it can corrupt the overall performance of the network\n",
        "# So we ignore the first 50 results during the training\n",
        "warmup_steps = 50\n",
        "\n",
        "def loss_mse_warmup(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the MSE between y_true and y_pred\n",
        "    Ignore the beginning 'warmup' steps of the sequences\n",
        "\n",
        "    :param y_true: desired output\n",
        "    :param y_pred: prediction made by model\n",
        "    :return: MSE between answer and prediction while ignoring the results from early stage\n",
        "    \"\"\"\n",
        "\n",
        "    y_true_slice = y_true[:, warmup_steps:, :]\n",
        "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
        "\n",
        "    loss = tf.losses.MSE(y_true_slice, y_pred_slice)\n",
        "    # It's unclear whether Keras reduce a tensor of losses to a scalar value or not.\n",
        "    # To ensure clarity, it's better to calculate the mean of the losses and return it.\n",
        "    loss_mean = tf.reduce_mean(loss)\n",
        "\n",
        "    return loss_mean"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import modules related to build a RNN\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import GRU, Dense, RepeatVector, TimeDistributed\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(units=128, activation='relu', return_sequences=True, input_shape=trainX_531.shape[-2:]))\n",
        "model.add(GRU(units=64, activation='relu', return_sequences=False))\n",
        "model.add(RepeatVector(trainY_531.shape[1]))\n",
        "model.add(GRU(units=64, activation='relu', return_sequences=True))\n",
        "model.add(GRU(units=128, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "\n",
        "optimizer = optimizers.RMSprop(lr=1e-3)     # learning rate = 0.001\n",
        "\n",
        "model.compile(loss=losses.mean_squared_error, optimizer=optimizer, metrics=[custom_loss])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_lr=1e-4, patience=0, verbose=1)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_reduce_lr]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split dataset into : train, test\n",
        "\n",
        "x_train, y_train, x_val, y_val = split_data(trainX_531, trainY_531, 0.1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64,epochs=30, validation_data=(x_val, y_val), verbose=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.save('gru_531_20200727.h5')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = load_model('../Data/Model/gru_531_20200727.h5', custom_objects = {'custom_loss' : custom_loss })"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pred_531 = model.predict(np.expand_dims(dataset[end_idx_531-96:end_idx_531], axis = 0))\n",
        "pred_531 = np.reshape(pred_531, pred_531.shape[-2:])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(pred_531)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Manually restore the data\n",
        "\n",
        "restored_vals = (energy_max - energy_min) * pred_531 + energy_min"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(restored_vals, label='Prediction of energy production on 5/31')\n",
        "plt.legend()\n",
        "plt.plot()\n",
        "\n",
        "# %% [markdown]\n",
        "# TimeSeries Cross Validation"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tscv = TimeSeriesSplit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "verbosity = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "acc_per_iter = []\n",
        "loss_per_iter = []"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_seq = trainX_531\n",
        "Y_seq = trainY_531"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "iter_num = 1\n",
        "for train_idx, test_idx in tscv.split(X_seq):\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=128, activation='relu', return_sequences=True, input_shape=trainX_531.shape[-2:]))\n",
        "    model.add(GRU(units=64, activation='relu', return_sequences=False))\n",
        "    model.add(RepeatVector(trainY_531.shape[1]))\n",
        "    model.add(GRU(units=64, activation='relu', return_sequences=True))\n",
        "    model.add(GRU(units=128, activation='relu', return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "\n",
        "    optimizer = optimizers.RMSprop(lr=1e-3)     # learning rate = 0.001\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=losses.mean_squared_error, optimizer=optimizer, metrics=[custom_loss])\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for {iter_num} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history = model.fit(X_seq[train_idx], Y_seq[train_idx],\n",
        "              batch_size=batch_size,\n",
        "              epochs=num_epochs,\n",
        "              verbose=verbosity)\n",
        "    \n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(X_seq[test_idx], Y_seq[test_idx], verbose=0)\n",
        "    print(f'Score for iteration {iter_num}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_iter.append(scores[1] * 100)\n",
        "    loss_per_iter.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    iter_num = iter_num + 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per iteration')\n",
        "for i in range(0, len(acc_per_iter)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_iter[i]} - Accuracy: {acc_per_iter[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_iter)} (+- {np.std(acc_per_iter)})')\n",
        "print(f'> Loss: {np.mean(loss_per_iter)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "timesplit_res = model.predict(np.expand_dims(X[end_idx_531-96:end_idx_531], axis = 0))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "timesplit_res"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "timesplit_res = np.reshape(timesplit_res, timesplit_res.shape[-2:])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(timesplit_res, label='5/31')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}